study_id,title,authors,year,database,doi_arxiv,abstract_snippet
S001,"Evaluating Large Language Models in Theory of Mind Tasks","Michal Kosinski",2023,arXiv,2302.02083,"ChatGPT-4 solved 75% of false-belief tasks, matching the performance of six-year-old children"
S002,"Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests","Max J. van Duijn, Bram M. A. van Dijk, Tom Kouwenhoven, Werner de Valk, Marco R. Spruit, Peter van der Putten",2023,arXiv,2310.20320,"Instruction-tuned GPT models outperformed other systems, with base-LLMs mostly unable to solve ToM tasks"
S003,"Deception Abilities Emerged in Large Language Models","Thilo Hagendorff",2023,arXiv,2307.16513,"Advanced LLMs demonstrated ability to understand and induce false beliefs in other agents"
S004,"Do Large Language Models know what humans know?","Sean Trott, Cameron Jones, Tyler Chang, James Michaelov, Benjamin Bergen",2022,arXiv,2209.01515,"GPT-3 showed sensitivity to others' beliefs but performed below human participants on false-belief tasks"
S005,"Doing Things with Words: Rethinking Theory of Mind Simulation in Large Language Models","Agnese Lombardi, Alessandro Lenci",2025,arXiv,2510.13395,"explores whether the Generative Agent-Based Model (GABM) Concordia can effectively model Theory of Mind (ToM) within simulated real-world environments"
S006,"SocialNLI: A Dialogue-Centric Social Inference Dataset","Akhil Deo, Kate Sanders, Benjamin Van Durme",2025,arXiv,2510.05458,"Making theory-of-mind inferences from human dialogue is a strong indicator of a model's underlying social abilities"
S007,"LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference","Fangzhou Liang, Tianshi Zheng, Chunkit Chan, Yauwai Yim, Yangqiu Song",2025,arXiv,2510.04980,"Effective multi-agent collaboration requires agents to infer the rationale behind others' actions"
S008,"TactfulToM: Do LLMs Have the Theory of Mind Ability to Understand White Lies?","Yiwei Liu, Emma Jane Pretty, Jiahao Huang, Saku Sugawara",2025,arXiv,2509.17054,"benchmark designed to evaluate LLMs' ability to understand white lies within real-life conversations"
S009,"Do Large Language Models Have a Planning Theory of Mind?","Jared Moore, Ned Cooper, Rasmus Overmark, Beba Cibralic, et al.",2025,arXiv,2507.16196,"planning theory of mind (PToM) task which requires agents to infer an interlocutor's beliefs and desires"
S010,"Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning","Sneheel Sarangi, Hanan Salam",2025,arXiv,2507.15788,"small LLMs struggle to develop a generic ToM capability through reinforcement learning"
S011,"MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind","Emilio Villa-Cueva, S M Masrur Ahmed, Rendi Chevi, et al.",2025,arXiv,2507.04415,"comprehensive benchmark designed to assess the ToM capabilities of multimodal large language models"
S012,"Theory of Mind in Action: The Instruction Inference Task","Fardin Saad, Pradeep K. Murukannaiah, Munindar P. Singh",2025,arXiv,2507.02935,"Theory of Mind (ToM) refers to an agent's capacity to infer the mental states of other agents"
S013,"SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions","Xianzhe Fan, Xuhui Zhou, Chuanyang Jin, et al.",2025,arXiv,2506.23046,"benchmark designed to evaluate multi-perspective ToM in embodied multi-agent complex social interactions"
S014,"Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models","Younwoo Choi, Changling Li, Yongjin Yang, Zhijing Jin",2025,arXiv,2506.22957,"understanding their awareness of both self-context and conversational partners is essential"
S015,"The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind","Andrei Lupu, Timon Willi, Jakob Foerster",2025,arXiv,2506.20664,"game-based benchmark for multi-agent reasoning and ToM to reason about the mental states of other agents"
S016,"Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting","Nathaniel Getachew, Abulhair Saparov",2025,arXiv,2506.19089,"programmable framework for synthetically generating stories to evaluate the theory of mind (ToM)"
S017,"Towards Safety Evaluations of Theory of Mind in Large Language Models","Tatsuhiro Aoshima, Mitsuaki Akiyama",2025,arXiv,2506.17352,"essential to investigate whether these behaviors stem from covert, intentional processes"
S018,"From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models","Xinyang Li, Siqi Liu, Bochao Zou, Jiansheng Chen, Huimin Ma",2025,arXiv,2506.14224,"interpretability-driven assessment of ToM in multimodal large language models (MLLMs)"
S019,"Can consciousness be observed from large language model internal states?","Jingkai Li",2025,arXiv,2506.22516,"apply IIT 3.0 and 4.0 to sequences of Large Language Model representations, analyzing data derived from existing Theory of Mind (ToM) test results"
S020,"Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning","Rebekah A. Gelpí, Eric Xue, William A. Cunningham",2025,arXiv,2507.03682,"hybrid approach to machine Theory of Mind (ToM) that uses large language models"
S021,"Spontaneous High-Order Generalization in Neural Theory-of-Mind Networks","Yiming Wang, Rui Wang",2025,arXiv,2509.25343,"neural networks could spontaneously generalize from first- to higher-order ToM without relying on advanced skills"
S022,"ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback","Matteo Bortoletto, Yichao Zhou, Lance Ying, Tianmin Shu, Andreas Bulling",2025,arXiv,2509.05091,"Theory of Mind-informed facilitator that promotes prosocial actions in multi-agent systems"
S023,"LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue","Katharine Kowalyshyn, Matthias Scheutz",2025,arXiv,2509.02292,"LLMs both as human-style annotators to track the team's shared mental models (SMMs)"
S024,"Validating Generative Agent-Based Models of Social Norm Enforcement","Logan Cross, Nick Haber, Daniel L. K. Yamins",2025,arXiv,2507.22049,"both persona-based individual differences and theory of mind capabilities are essential"
S025,"Towards Cognitive Synergy in LLM-Based Multi-Agent Systems","Adam Kostka, Jarosław A. Chudziak",2025,arXiv,2507.21969,"adaptive theory of mind (ToM) and systematic critical evaluation enable collaboration"
S026,"Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges","Patrick Taillandier, Jean Daniel Zucker, Arnaud Grignard, et al.",2025,arXiv,2507.19364,"ability of LLMs to replicate key aspects of human cognition, including Theory of Mind reasoning"
S027,"DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration","Xiyun Li, Yining Ding, Yuhua Jiang, et al.",2025,arXiv,2507.14088,"multi-scale theory of mind (ToM) module to facilitate robust human partner modeling"
S028,"A validity-guided workflow for robust large language model research in psychology","Zhicheng Lin",2025,arXiv,2507.04491,"theory-of-mind accuracy varies widely with trivial rephrasing demonstrating measurement issues"
S029,"Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning","Lance Ying, Ryan Truong, Katherine M. Collins, et al.",2025,arXiv,2506.16755,"multimodal social reasoning as a process of constructing structured but situation-specific agent representations"
S030,"MIST: Towards Multi-dimensional Implicit BiaS Evaluation of LLMs via Theory of Mind","Yanlin Li, Hao Liu, Huimin Liu, Kun Wang, Yinwei Wei, Yupeng Hu",2025,arXiv,2506.14161,"Theory of Mind (ToM) used for bias evaluation methodology"