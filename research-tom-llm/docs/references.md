# Complete References

## Primary Studies Included in Systematic Review (n=28)

1. Aoshima, T., & Akiyama, M. (2025). Towards Safety Evaluations of Theory of Mind in Large Language Models. *arXiv preprint arXiv:2506.17352*.

2. Bortoletto, M., Zhou, Y., Ying, L., Shu, T., & Bulling, A. (2025). ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback. *arXiv preprint arXiv:2509.05091*.

3. Choi, Y., Li, C., Yang, Y., & Jin, Z. (2025). Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models. *arXiv preprint arXiv:2506.22957*.

4. Cross, L., Haber, N., & Yamins, D. L. K. (2025). Validating Generative Agent-Based Models of Social Norm Enforcement. *arXiv preprint arXiv:2507.22049*.

5. Deo, A., Sanders, K., & Van Durme, B. (2025). SocialNLI: A Dialogue-Centric Social Inference Dataset. *arXiv preprint arXiv:2510.05458*.

6. Fan, X., Zhou, X., Jin, C., et al. (2025). SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions. *arXiv preprint arXiv:2506.23046*.

7. Gelp√≠, R. A., Xue, E., & Cunningham, W. A. (2025). Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning. *arXiv preprint arXiv:2507.03682*.

8. Getachew, N., & Saparov, A. (2025). Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting. *arXiv preprint arXiv:2506.19089*.

9. Hagendorff, T. (2023). Deception Abilities Emerged in Large Language Models. *arXiv preprint arXiv:2307.16513*.

10. Kosinski, M. (2023). Evaluating Large Language Models in Theory of Mind Tasks. *arXiv preprint arXiv:2302.02083*.

11. Kostka, A., & Chudziak, J. A. (2025). Towards Cognitive Synergy in LLM-Based Multi-Agent Systems. *arXiv preprint arXiv:2507.21969*.

12. Kowalyshyn, K., & Scheutz, M. (2025). LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue. *arXiv preprint arXiv:2509.02292*.

13. Li, J. (2025). Can consciousness be observed from large language model internal states? *arXiv preprint arXiv:2506.22516*.

14. Li, X., Ding, Y., Jiang, Y., et al. (2025). DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration. *arXiv preprint arXiv:2507.14088*.

15. Li, X., Liu, S., Zou, B., Chen, J., & Ma, H. (2025). From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models. *arXiv preprint arXiv:2506.14224*.

16. Li, Y., Liu, H., Liu, H., Wang, K., Wei, Y., & Hu, Y. (2025). MIST: Towards Multi-dimensional Implicit BiaS Evaluation of LLMs via Theory of Mind. *arXiv preprint arXiv:2506.14161*.

17. Liang, F., Zheng, T., Chan, C., Yim, Y., & Song, Y. (2025). LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference. *arXiv preprint arXiv:2510.04980*.

18. Lin, Z. (2025). A validity-guided workflow for robust large language model research in psychology. *arXiv preprint arXiv:2507.04491*.

19. Liu, Y., Pretty, E. J., Huang, J., & Sugawara, S. (2025). TactfulToM: Do LLMs Have the Theory of Mind Ability to Understand White Lies? *arXiv preprint arXiv:2509.17054*.

20. Lombardi, A., & Lenci, A. (2025). Doing Things with Words: Rethinking Theory of Mind Simulation in Large Language Models. *arXiv preprint arXiv:2510.13395*.

21. Lupu, A., Willi, T., & Foerster, J. (2025). The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind. *arXiv preprint arXiv:2506.20664*.

22. Moore, J., Cooper, N., Overmark, R., Cibralic, B., et al. (2025). Do Large Language Models Have a Planning Theory of Mind? *arXiv preprint arXiv:2507.16196*.

23. Saad, F., Murukannaiah, P. K., & Singh, M. P. (2025). Theory of Mind in Action: The Instruction Inference Task. *arXiv preprint arXiv:2507.02935*.

24. Sarangi, S., & Salam, H. (2025). Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning. *arXiv preprint arXiv:2507.15788*.

25. Taillandier, P., Zucker, J. D., Grignard, A., et al. (2025). Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges. *arXiv preprint arXiv:2507.19364*.

26. Trott, S., Jones, C., Chang, T., Michaelov, J., & Bergen, B. (2022). Do Large Language Models know what humans know? *arXiv preprint arXiv:2209.01515*.

27. van Duijn, M. J., van Dijk, B. M. A., Kouwenhoven, T., de Valk, W., Spruit, M. R., & van der Putten, P. (2023). Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests. *arXiv preprint arXiv:2310.20320*.

28. Villa-Cueva, E., Ahmed, S. M. M., Chevi, R., et al. (2025). MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind. *arXiv preprint arXiv:2507.04415*.

29. Ying, L., Truong, R., Collins, K. M., et al. (2025). Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning. *arXiv preprint arXiv:2506.16755*.

## Methodological References

30. Page, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., ... & Moher, D. (2021). The PRISMA 2020 statement: an updated guideline for reporting systematic reviews. *BMJ*, 372, n71.

31. Cohen, J. (1960). A coefficient of agreement for nominal scales. *Educational and Psychological Measurement*, 20(1), 37-46.

32. Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for categorical data. *Biometrics*, 33(1), 159-174.

## Theory of Mind Background References

33. Baron-Cohen, S., Leslie, A. M., & Frith, U. (1985). Does the autistic child have a "theory of mind"? *Cognition*, 21(1), 37-46.

34. Premack, D., & Woodruff, G. (1978). Does the chimpanzee have a theory of mind? *Behavioral and Brain Sciences*, 1(4), 515-526.

35. Wellman, H. M., Cross, D., & Watson, J. (2001). Meta-analysis of theory-of-mind development: The truth about false belief. *Child Development*, 72(3), 655-684.

## Related AI and Cognitive Science References

36. Lake, B. M., Ullman, T. D., Tenenbaum, J. B., & Gershman, S. J. (2017). Building machines that learn and think like people. *Behavioral and Brain Sciences*, 40, e253.

37. Marcus, G. (2020). The next decade in AI: Four steps towards robust artificial intelligence. *arXiv preprint arXiv:2002.06177*.

38. Mitchell, M. (2021). Abstraction and analogy-making in artificial intelligence. *Annals of the New York Academy of Sciences*, 1505(1), 79-101.

39. Rabinowitz, N., Perbet, F., Song, F., Zhang, C., Eslami, S. A., & Botvinick, M. (2018). Machine theory of mind. *Proceedings of the International Conference on Machine Learning*, 4218-4227.

40. Sap, M., Rashkin, H., Chen, D., Le Bras, R., & Choi, Y. (2019). Social IQa: Commonsense reasoning about social interactions. *Proceedings of the Conference on Empirical Methods in Natural Language Processing*, 4463-4473.

## Large Language Model References

41. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. *Advances in Neural Information Processing Systems*, 33, 1877-1901.

42. OpenAI. (2023). GPT-4 Technical Report. *arXiv preprint arXiv:2303.08774*.

43. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M. A., Lacroix, T., ... & Lample, G. (2023). LLaMA: Open and efficient foundation language models. *arXiv preprint arXiv:2302.13971*.

44. Anthropic. (2024). The Claude 3 Model Family: Opus, Sonnet, Haiku. *Anthropic Technical Report*.

45. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, 35, 24824-24837.

---

*Note: All arXiv references represent preprints that may have been subsequently published in peer-reviewed venues. DOIs and final publication details should be verified for citation purposes.*