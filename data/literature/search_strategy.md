# Systematic Literature Review: Creativity and Planning in LLMs
## Search Strategy Documentation

**Date:** November 14, 2024
**Review Type:** PRISMA 2020 Systematic Review
**Focus:** Creativity, innovation, and sequential planning capabilities in large language models

### Research Questions
1. How are creativity and divergent thinking evaluated in LLMs?
2. What planning and reasoning capabilities do LLMs demonstrate?
3. Can LLMs generate novel ideas comparable to human creativity?

### Search Terms and Boolean Operators

#### Creativity Domain
- ("creativity" OR "creative thinking" OR "divergent thinking") AND ("large language model" OR "LLM" OR "GPT" OR "transformer")
- ("novel idea generation" OR "ideation" OR "creative problem solving") AND ("language model" OR "AI" OR "artificial intelligence")
- ("creative writing" OR "story generation" OR "poetry generation") AND ("LLM" OR "transformer") AND ("evaluation" OR "assessment")

#### Planning & Reasoning Domain
- ("planning" OR "task planning" OR "sequential planning") AND ("language model" OR "LLM")
- ("chain of thought" OR "CoT" OR "reasoning chains") AND ("transformer" OR "GPT")
- ("multi-step reasoning" OR "complex reasoning" OR "logical reasoning") AND ("language model")

#### Innovation & Ideation
- ("scientific ideation" OR "research ideation" OR "hypothesis generation") AND ("AI" OR "LLM")
- ("innovation" OR "novelty" OR "originality") AND ("language model" OR "transformer")

### Databases Searched
1. **OpenAlex** - Comprehensive academic database
2. **arXiv** - Preprint server for CS/AI research
3. **Semantic Scholar** - AI-powered research tool

### Date Range
- January 1, 2020 - December 31, 2025

### Inclusion Criteria
1. Papers evaluating creative capabilities in LLMs
2. Papers on planning and sequential reasoning in LLMs
3. Papers comparing LLM vs human creativity
4. Papers on novel idea generation using LLMs
5. Published between 2020-2025
6. Empirical evaluation included
7. English language
8. Peer-reviewed or preprints

### Exclusion Criteria
1. Papers only on image generation (without text creativity)
2. Papers without empirical evaluation
3. Tutorial or survey papers without novel findings
4. Papers not directly evaluating LLM capabilities
5. Non-English papers
6. Conference abstracts without full papers

### Data Extraction Schema
- **Study Identifier**: Unique ID
- **Citation**: Authors, Year, Title, Venue
- **Task Type**: Creativity/Planning/Reasoning category
- **Models Tested**: Which LLMs evaluated
- **Evaluation Metrics**: How creativity/planning measured
- **Human Baseline**: If human comparison included
- **Key Findings**: Main results
- **Novelty Assessment**: How novelty evaluated
- **Limitations**: Identified limitations
- **Dataset/Benchmark**: What data used

### Search Execution Date
- Initial search: November 14, 2024
- Search strategy finalized: November 14, 2024

### Quality Assessment
- Will use adapted criteria for AI evaluation studies
- Focus on: reproducibility, evaluation rigor, baseline comparisons