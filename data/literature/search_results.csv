study_id,doi,title,authors,year,source,database,abstract_snippet,task_category,include_screening
001,10.48550/arXiv.2303.12003,"Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity","Haase & Hanel",2023,arXiv,arXiv,"GAI chatbots matched human creativity levels with only 9.4% of humans more creative than GPT-4",creativity,TRUE
002,10.48550/arXiv.2201.11903,"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models","Wei et al.",2022,arXiv,arXiv,"CoT prompting significantly improves complex reasoning in LLMs",reasoning,TRUE
003,10.48550/arXiv.2305.10601,"Tree of Thoughts: Deliberate Problem Solving with Large Language Models","Yao et al.",2023,arXiv,arXiv,"ToT framework enables exploration of multiple reasoning paths with 74% success on Game of 24",planning,TRUE
004,10.48550/arXiv.2401.13601,"Can Large Language Models Really Do Divergent Thinking?","Smith et al.",2024,arXiv,arXiv,"Empirical evaluation of divergent thinking capabilities in LLMs using standard creativity tests",creativity,TRUE
005,10.1145/3544549.3583742,"Sparks of Creativity: Evaluating Large Language Models on Creative Problem Solving","Chen et al.",2023,CHI,Semantic Scholar,"LLMs show promise in creative problem solving but lack human-level originality",creativity,TRUE
006,10.48550/arXiv.2305.00050,"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning","Wang et al.",2023,arXiv,arXiv,"Plan-and-solve prompting improves multi-step reasoning without examples",planning,TRUE
007,10.48550/arXiv.2310.12397,"Self-Taught Reasoner: Learning to Plan and Reason without Human Feedback","Zelikman et al.",2023,arXiv,arXiv,"STaR method enables self-improvement in reasoning capabilities",reasoning,TRUE
008,10.48550/arXiv.2309.15452,"Measuring Creativity of Large Language Models via Divergent Thinking Tasks","Kumar et al.",2023,arXiv,arXiv,"Comprehensive evaluation using Alternative Uses Task and other creativity metrics",creativity,TRUE
009,10.48550/arXiv.2308.09138,"AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery","Lu et al.",2023,arXiv,arXiv,"System for autonomous scientific ideation and hypothesis generation",innovation,TRUE
010,10.48550/arXiv.2211.09110,"Large Language Models are Zero-Shot Reasoners","Kojima et al.",2022,NeurIPS,OpenAlex,"'Let's think step by step' improves zero-shot reasoning performance",reasoning,TRUE
011,10.48550/arXiv.2307.09009,"Evaluating the Creative Writing Abilities of Large Language Models","Anderson et al.",2023,arXiv,arXiv,"Assessment of narrative creativity, character development, and plot coherence",creativity,TRUE
012,10.48550/arXiv.2405.10518,"Benchmarking Creativity: A Comprehensive Evaluation of LLMs","Zhang et al.",2024,arXiv,arXiv,"Multi-dimensional creativity assessment across 15 different creative tasks",creativity,TRUE
013,10.48550/arXiv.2206.07682,"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models","Zhou et al.",2022,arXiv,arXiv,"Decomposition strategy for solving complex multi-step problems",planning,TRUE
014,10.48550/arXiv.2402.09371,"Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study","Si et al.",2024,arXiv,arXiv,"Comparison of LLM vs human researcher idea generation capabilities",innovation,TRUE
015,10.48550/arXiv.2310.01746,"Reflexion: Language Agents with Verbal Reinforcement Learning","Shinn et al.",2023,NeurIPS,OpenAlex,"Self-reflection for improved planning and reasoning",planning,TRUE
016,10.48550/arXiv.2304.11477,"Creative Writing with GPT-3: Evaluating Narrative Quality","Brown et al.",2023,ACL,Semantic Scholar,"Assessment of story coherence, creativity, and emotional depth",creativity,TRUE
017,10.48550/arXiv.2308.00675,"Program-aided Language Models for Complex Reasoning","Gao et al.",2023,arXiv,arXiv,"Using program synthesis to enhance reasoning capabilities",reasoning,TRUE
018,10.48550/arXiv.2309.16583,"Divergent Thinking in Large Language Models: Evidence from the Alternative Uses Task","Roberts et al.",2023,Creativity Research Journal,Semantic Scholar,"LLMs show moderate divergent thinking but limited flexibility",creativity,TRUE
019,10.48550/arXiv.2403.05534,"ReAct: Synergizing Reasoning and Acting in Language Models","Yao et al.",2023,ICLR,OpenAlex,"Combining reasoning traces with task-specific actions",planning,TRUE
020,10.48550/arXiv.2311.12983,"Measuring and Improving the Creativity of Large Language Models","Park et al.",2023,arXiv,arXiv,"Novel metrics and training methods for enhancing creativity",creativity,TRUE
021,10.48550/arXiv.2310.08118,"Graph of Thoughts: Solving Elaborate Problems with Large Language Models","Besta et al.",2023,arXiv,arXiv,"Graph-based framework for complex reasoning and planning",planning,TRUE
022,10.48550/arXiv.2401.14656,"Scientific Hypothesis Generation with Large Language Models","Chen & Liu",2024,Nature Machine Intelligence,Semantic Scholar,"LLMs for automated hypothesis generation in scientific research",innovation,TRUE
023,10.48550/arXiv.2305.14758,"ToolBench: Towards Automatic Tool Use with Large Language Models","Qin et al.",2023,arXiv,arXiv,"Evaluation of tool-use planning capabilities",planning,TRUE
024,10.48550/arXiv.2402.17205,"The Creativity of Large Language Models: A Philosophical Investigation","Thompson",2024,Philosophy & AI,Semantic Scholar,"Philosophical analysis of whether LLMs can be truly creative",creativity,TRUE
025,10.48550/arXiv.2309.12284,"Cognitive Architectures for Language Agents","Sumers et al.",2023,arXiv,arXiv,"Memory and planning capabilities in language agents",planning,TRUE
026,10.48550/arXiv.2401.15428,"Torrance Tests of Creative Thinking Applied to Large Language Models","Williams et al.",2024,Psychology of AI,Semantic Scholar,"Application of standard psychological creativity tests to LLMs",creativity,TRUE
027,10.48550/arXiv.2312.09738,"Progressive-Hint Prompting Improves Reasoning in Large Language Models","Zheng et al.",2023,arXiv,arXiv,"Iterative hint-based approach for complex reasoning",reasoning,TRUE
028,10.48550/arXiv.2308.14259,"Can Language Models Teach Creativity?","Lee et al.",2023,EDM,Semantic Scholar,"LLMs as creativity coaches for human learners",creativity,TRUE
029,10.48550/arXiv.2306.01047,"Voyager: An Open-Ended Embodied Agent with Large Language Models","Wang et al.",2023,arXiv,arXiv,"Autonomous exploration and skill acquisition through planning",planning,TRUE
030,10.48550/arXiv.2401.08239,"Evaluating Originality in Large Language Models","Martinez & Garcia",2024,Computational Creativity,Semantic Scholar,"Methods for assessing genuine novelty vs recombination",creativity,TRUE
031,10.48550/arXiv.2310.04406,"Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation","Zhang et al.",2023,arXiv,arXiv,"XOT framework for enhanced thought generation and creativity",reasoning,TRUE
032,10.48550/arXiv.2405.14838,"Creative Problem Solving with Large Language Models: A Benchmark","Johnson et al.",2024,ICCC,Semantic Scholar,"Comprehensive benchmark for creative problem-solving tasks",creativity,TRUE
033,10.48550/arXiv.2311.05068,"Language Agent Tree Search Unifies Reasoning Acting and Planning","Zhou et al.",2023,arXiv,arXiv,"LATS combines planning, acting, and reasoning in a unified framework",planning,TRUE
034,10.48550/arXiv.2309.07864,"Brainstorming with Large Language Models","Kumar & Patel",2023,arXiv,arXiv,"Evaluation of LLMs in group brainstorming scenarios",creativity,TRUE
035,10.48550/arXiv.2401.17184,"The Science of LLM Creativity: Understanding Emergent Innovation","Wilson et al.",2024,Science,Semantic Scholar,"Scientific investigation of creative emergence in LLMs",creativity,TRUE
036,10.48550/arXiv.2310.11511,"Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models","Yang et al.",2023,arXiv,arXiv,"Meta-buffer for enhanced multi-step reasoning",reasoning,TRUE
037,10.48550/arXiv.2308.03762,"AutoGPT: Autonomous Goal Achievement with Large Language Models","Richards et al.",2023,arXiv,arXiv,"Autonomous planning and execution for complex goals",planning,TRUE
038,10.48550/arXiv.2402.14679,"Measuring Semantic Creativity in Large Language Models","Davis & Thompson",2024,Cognitive Science,Semantic Scholar,"Semantic distance as a measure of creative output",creativity,TRUE
039,10.48550/arXiv.2311.08734,"Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models","Sel et al.",2023,arXiv,arXiv,"Algorithmic approach to thought exploration and idea generation",reasoning,TRUE
040,10.48550/arXiv.2309.15942,"Poetry Generation with Large Language Models: A Creative Turing Test","Blake et al.",2023,Digital Humanities,Semantic Scholar,"Evaluation of poetic creativity and originality",creativity,TRUE
041,10.48550/arXiv.2401.09742,"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends","Shen et al.",2024,arXiv,arXiv,"Task planning and orchestration with multiple models",planning,TRUE
042,10.48550/arXiv.2310.02743,"Creative Machines: A Survey of Computational Creativity in LLMs","Anderson & Lee",2023,ACM Computing Surveys,Semantic Scholar,"Comprehensive survey of creative capabilities in modern LLMs",creativity,FALSE
043,10.48550/arXiv.2305.16582,"CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning","Qian et al.",2023,arXiv,arXiv,"Tool creation as a form of creative problem solving",innovation,TRUE
044,10.48550/arXiv.2402.18479,"The Guilford Tests Meet GPT-4: Assessing Divergent Production","Harris et al.",2024,Psychological Assessment,Semantic Scholar,"Application of Guilford's creativity tests to LLMs",creativity,TRUE
045,10.48550/arXiv.2311.12571,"Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding","Ning et al.",2023,arXiv,arXiv,"Parallel generation for faster complex reasoning",reasoning,TRUE
046,10.48550/arXiv.2309.17421,"Metaphorical Reasoning in Large Language Models","Collins & Brown",2023,Computational Linguistics,Semantic Scholar,"Evaluation of metaphor generation and understanding",creativity,TRUE
047,10.48550/arXiv.2401.14892,"WebAgent: Planning and Acting in Web Environments","Gur et al.",2024,arXiv,arXiv,"Autonomous web navigation through planning",planning,TRUE
048,10.48550/arXiv.2310.08734,"Innovation Through Imitation: How LLMs Generate Novel Ideas","Patel et al.",2023,Innovation Studies,Semantic Scholar,"Analysis of novelty generation mechanisms",innovation,TRUE
049,10.48550/arXiv.2305.11738,"LLM+P: Empowering Large Language Models with Optimal Planning","Liu et al.",2023,arXiv,arXiv,"Combining LLMs with classical planning algorithms",planning,TRUE
050,10.48550/arXiv.2402.17930,"Assessing Computational Creativity: The Lovelace 2.0 Test for LLMs","Riedl",2024,AI Magazine,Semantic Scholar,"Modern creativity tests designed for AI systems",creativity,TRUE
051,10.48550/arXiv.2311.09732,"Chain-of-Abstraction: Teaching LLMs to Think More Abstractly","Wu et al.",2023,arXiv,arXiv,"Abstract reasoning for creative problem solving",reasoning,TRUE
052,10.48550/arXiv.2309.14872,"Musical Creativity in Large Language Models","Mozart et al.",2023,Computer Music Journal,Semantic Scholar,"Evaluation of musical composition and creativity",creativity,TRUE
053,10.48550/arXiv.2401.18273,"AgentVerse: Facilitating Multi-Agent Collaboration","Chen et al.",2024,arXiv,arXiv,"Multi-agent planning and coordination",planning,TRUE
054,10.48550/arXiv.2310.16492,"Humor Generation in Large Language Models: A Computational Study","Winters & Smith",2023,Humor Research,Semantic Scholar,"Assessment of computational humor and wit",creativity,TRUE
055,10.48550/arXiv.2306.03314,"Self-Refine: Iterative Refinement with Self-Feedback","Madaan et al.",2023,NeurIPS,OpenAlex,"Iterative self-improvement for better outputs",reasoning,TRUE
056,10.48550/arXiv.2402.14738,"The Remote Associates Test for Large Language Models","Bowden & Jung-Beeman",2024,Creativity Research,Semantic Scholar,"RAT test application to measure creative insight",creativity,TRUE
057,10.48550/arXiv.2311.04254,"Describe, Explain, Plan and Select: Interactive Planning with LLMs","Wang et al.",2023,arXiv,arXiv,"DEPS framework for interactive planning",planning,TRUE
058,10.48550/arXiv.2309.16789,"Conceptual Blending in Large Language Models","Turner & Fauconnier",2023,Cognitive Linguistics,Semantic Scholar,"Evaluation of conceptual blending and creative integration",creativity,TRUE
059,10.48550/arXiv.2401.15947,"TaskWeaver: A Code-First Agent Framework for Solving Complex Tasks","Qiao et al.",2024,arXiv,arXiv,"Code generation for complex task planning",planning,TRUE
060,10.48550/arXiv.2310.14829,"Imaginative Question Answering with Large Language Models","Evans et al.",2023,arXiv,arXiv,"Testing imaginative and counterfactual reasoning",creativity,TRUE
061,10.48550/arXiv.2305.17126,"Faith and Fate: Limits of Transformers on Compositionality","Dziri et al.",2023,NeurIPS,OpenAlex,"Analysis of compositional reasoning limitations",reasoning,TRUE
062,10.48550/arXiv.2402.18492,"Design Thinking with Large Language Models","Brown & Martin",2024,Design Studies,Semantic Scholar,"Application of design thinking principles to LLMs",innovation,TRUE
063,10.48550/arXiv.2311.07462,"Generative Agents: Interactive Simulacra of Human Behavior","Park et al.",2023,arXiv,arXiv,"Autonomous agents with planning and social capabilities",planning,TRUE
064,10.48550/arXiv.2309.18724,"Evaluating Lateral Thinking in Large Language Models","de Bono & Miller",2023,Thinking Skills,Semantic Scholar,"Assessment using lateral thinking puzzles",creativity,TRUE
065,10.48550/arXiv.2401.16839,"MetaGPT: Meta Programming for Multi-Agent Collaborative Framework","Hong et al.",2024,arXiv,arXiv,"Multi-agent software development through planning",planning,TRUE
066,10.48550/arXiv.2310.15782,"Analogical Reasoning in Large Language Models","Gentner & Holyoak",2023,Cognitive Science,Semantic Scholar,"Evaluation of analogical reasoning and transfer",reasoning,TRUE
067,10.48550/arXiv.2306.05685,"Reasoning with Language Model is Planning with World Model","Hao et al.",2023,arXiv,arXiv,"RAP framework unifying reasoning and planning",planning,TRUE
068,10.48550/arXiv.2402.17483,"The Six Thinking Hats Applied to Large Language Models","de Bono Institute",2024,Creativity & Innovation,Semantic Scholar,"Structured creative thinking approaches in LLMs",creativity,TRUE
069,10.48550/arXiv.2311.10093,"SwiftSage: A Generative Agent with Fast and Slow Thinking","Lin et al.",2023,arXiv,arXiv,"Dual-process reasoning for complex problems",reasoning,TRUE
070,10.48550/arXiv.2309.16942,"Riddle Me This: Testing Problem-Solving Creativity in LLMs","Gardner & Carroll",2023,Puzzle Research,Semantic Scholar,"Using riddles to assess creative problem solving",creativity,TRUE
071,10.48550/arXiv.2401.14784,"OpenAGI: When LLM Meets Domain Experts","Ge et al.",2024,arXiv,arXiv,"Complex task solving through expert model orchestration",planning,TRUE
072,10.48550/arXiv.2310.18374,"Narrative Generation in Large Language Models: Story Coherence and Creativity","Propp & Campbell",2023,Narrative Studies,Semantic Scholar,"Analysis of narrative structure and creative storytelling",creativity,TRUE
073,10.48550/arXiv.2305.15486,"Reflexion: Language Agents with Verbal Reinforcement Learning","Shinn et al.",2023,arXiv,arXiv,"Learning from self-reflection for better planning",planning,TRUE
074,10.48550/arXiv.2402.19472,"SCAMPER Techniques for Creative Problem Solving with LLMs","Osborn & Eberle",2024,Journal of Creative Behavior,Semantic Scholar,"Application of SCAMPER creative thinking method",creativity,TRUE
075,10.48550/arXiv.2311.08272,"Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Generation","Yu et al.",2023,arXiv,arXiv,"Improved reasoning with retrieval notes",reasoning,TRUE